{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "1. 목적 : y_predict와 y를 비교 (모델의 정량적 검증)\n",
    "2. Classification 문제에서의 evaluation metric 방법\n",
    "* accuracy (e.g. 'Titanic'의 Kaggle score)\n",
    "- y_predict와 y값과의 일치도\n",
    "- classification 문제에 적합\n",
    "- regression 문제에는 부적합 (정답에 근사하는 것도 의미있는데 'accuracy' 관점에서는 정답이 아니면 틀린 것으로 간주)\n",
    "3. Regression 문제에서의 evaluation metric 방법\n",
    "* $MAE=\\frac{1}{n}\\sum_{i=1}^n|y_i-\\hat{y_i}|$\n",
    "\n",
    "* $MSE=\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2$ &rarr; 편차가 큰 outlier에 대해 보다 더 민감하게 반응\n",
    "\n",
    "* $RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언제 MAE? 언제 MSE or RMSE?\n",
    "* 1차검증 : Python 이용 가설-검증 단계\n",
    "* 2차선택: 각 회사의 부서마다 설정된 KPI 지표의 특성에 따라 MAE or MSE/RMSE 지표 중 1개 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPI (Key Performance Index, 핵심 성과 지표)\n",
    "1. Naver에서 main page 유지 담당부서\n",
    "* KPI: daily active users (DAU) = 하루 동안 몇 명이 방문하는가?\n",
    "* 많이 방문할수록 광고에 많이 노출\n",
    "2. YouTube 조회수 담당부서\n",
    "* KPI: 잔존시간(1명의 user가 들어왔을 때 동영상 시청시간)\n",
    "* 많이 시청할수록 광고에 많이 노출\n",
    "3. 전자상거래 or 쇼핑몰 (2개의 KPI 동시 사용)\n",
    "* CAC(Customer Acquisition Cost): 자사 쇼핑몰에 1명의 고객을 모셔오기 위해 소요되는 광고비\n",
    "* LTV (Life Time Value): 그 고객이 자사에 남겨주는 수익\n",
    "    * LTV = CAC - 서비스 상으로 적자도 흑자도 아님\n",
    "    * LTV > 3*CAC - 운영비, 인건비 비용 고려시 적정 수익\n",
    "4. 카카오 네비게이션 (KPI: 제시되는 도착예정시간의 정확도)\n",
    "* 제시된 도착예정시간과 실제 소요시간까지의 gap이 크면 클수록 서비스 불만 폭주 -> outlier에 가중치를 둘 수 있는 MSE, RMSE 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSLE\n",
    "* 제안된 예정시간보다 실제 도착시간이 짧은 경우 가중치를 덜 주는 방향으로 evaluation metric을 tunig 할 필요가 있음\n",
    "* &rarr; RMSLE (Root Mean Squared Logarithmic Error)\n",
    "* Bike Sharing Demand에서의 score = RMSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$RMSLE=\\sqrt{\\frac{1}{n}\\sum^n_{i=1}(log(y_i+1)-log(\\hat{y}+1))^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "* Model A\n",
    "    * 100개의 표본에서 100개의 예측치 도출. 예측치 중 99개는 정답, 1개는 오답(정답으로부터 200만큼 차이)\n",
    "* Model B\n",
    "    * 100개의 표본에서 100개의 예측치 도출\n",
    "    * 예측치 모두 오답 (각각 정답으로부터 2만큼 차이)\n",
    "\n",
    "* MAE (200/100 vs 200/100)\n",
    "    * Model A의 MAE = Model B의 MAE (두 모델을 동일하게 생각)\n",
    "\n",
    "* MSE (40000/100 vs 400/100) or RMSE (20 vs 2)\n",
    "    * Model A> Model B (Model B가 바람직한 model이라고 생각)\n",
    "    * 1개의 outlier에 대해서 민감하게 반응\n",
    "\n",
    "* RMSLE\n",
    "    * Model A < Model B (Model A가 바람직한 model이라고 생각)\n",
    "    * 1개를 확실히 틀리는 것이, 100개를 작게 틀리는 것보다 선호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 검증 방법 비교\n",
    "\n",
    "* MAE (with regard to MSE, RMSE)\n",
    "    * 정답에서, 단순히 정량적으로 얼만큼 차이가 있는지에 관심이 있는 경우\n",
    "* MSE vs RMSE\n",
    "    * 취향 차이\n",
    "* RMSLE VS (MSE, RMSE)\n",
    "    * MSE, RMSE\n",
    "        * 품질에서 1개라도 불량품이 나오면 고객의 항의가 빗발치는 상품의 경우\n",
    "        * 네비게이션의 도착예정시간\"처럼 정답에 가깝게 근접하는 것이 중요한 경우\n",
    "    * RMSLE\n",
    "        * 정답에 근사하는 것이 아닌, 정답을 맞추는 것이 훨씬 중요한 경우\n",
    "        * 1~2개의 극단적인 outliers 정도는 크게 상관이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
